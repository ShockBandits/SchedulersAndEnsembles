{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fakeENS:\n",
    "    def __init__(self, num_classifier, num_class, \n",
    "                 real_labels = None, confMat = None, alpha = None, \n",
    "                 excess_acc = np.array([0.8, 0.5, 0.3])):\n",
    "        '''\n",
    "        num_classifier: number of classifiers\n",
    "        num_class: number of classes\n",
    "        real_labels: stream of the real labels\n",
    "        alpha: minimum accuracy of the classifiers\n",
    "        excess_acc: excess accuracy of the classifiers\n",
    "        '''\n",
    "        self.num_class = num_class\n",
    "        self.num_classifier = num_classifier\n",
    "        #minimum accuracy per worker\n",
    "        if confMat is None:\n",
    "            if alpha is None:\n",
    "                alpha_p = [0.5, 0.3, 0.2] # probability of choosing alpha from alpha_arr \n",
    "                self.alpha = np.random.choice(excess_acc, p = alpha_p, \n",
    "                                              size = (num_classifier, num_class))\n",
    "            else:\n",
    "                self.alpha = alpha  \n",
    "            #------------------------\n",
    "            # generate the confusion matrices\n",
    "            self.confMat = {i: self.__genConfMat(self.alpha[i,:]) for i in range(self.num_classifier)} \n",
    "        else:\n",
    "            self.confMat = confMat.copy()\n",
    "        # real labels storage\n",
    "        self.real_labels = real_labels\n",
    "        #--------used to fix the classification-------\n",
    "        self.a = np.random.randint(100); \n",
    "        self.b = np.random.randint(1000, 2000);\n",
    "    \n",
    "    def reshuffle(self):\n",
    "        self.a = np.random.randint(100); \n",
    "        self.b = np.random.randint(1000, 2000); \n",
    "        \n",
    "    def newSamples(self, real_labels):\n",
    "        # real labels storage\n",
    "        self.real_labels = real_labels\n",
    "        \n",
    "    def getConfMat(self):\n",
    "        return self.confMat\n",
    "        \n",
    "    def __genConfMat(self, alpha = None):\n",
    "    # k is the size of the confusion matrix\n",
    "    # alpha is the lower limit for the diagonal entry\n",
    "        if alpha is None: alpha = 0.51*np.ones(self.num_class)\n",
    "        rho = 1e-6\n",
    "        normP = lambda x: np.maximum(x, rho)/np.sum(np.maximum(x, rho))\n",
    "        k = self.num_class\n",
    "        C = np.array([np.random.rand(k) for i in range(k)])\n",
    "        for i in range(k): \n",
    "            C[i,i] = alpha[i] + np.max(C[i,:]);\n",
    "            C[i,:] = normP(C[i,:])\n",
    "        return C    \n",
    "        \n",
    "    def classify(self, schedule):\n",
    "        #print 'sch_input:',schedule\n",
    "        new_labels = np.zeros(self.num_classifier)\n",
    "        #print 'schedule:', schedule\n",
    "        for i, sample_id in enumerate(schedule):\n",
    "            #----------------------------\n",
    "            if sample_id >= 1: \n",
    "                # Seed to make labelling deterministic\n",
    "                np.random.seed(int(self.a*sample_id+self.b*i))\n",
    "                h = self.real_labels[int(sample_id - 1)]\n",
    "                l = np.random.choice(range(self.num_class), p = self.confMat[i][int(h),:])\n",
    "                new_labels[i] = l+1 # label 0 resereved for null label\n",
    "                #print 'sample id:', sample_id, 'classifier:', i, 'seed:', seed, 'label:', l+1\n",
    "        return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_arr(arr, mode = 'float'):\n",
    "    if mode == 'int':\n",
    "        return \" \".join(\"%d\"%x for x in arr)\n",
    "    else:\n",
    "        return \" \".join(\"%.3f\"%x for x in arr)\n",
    "\n",
    "def averageAcc(p_true, C):\n",
    "    ''' Accuracy for each class, weighted by class\n",
    "        frequency'''\n",
    "    return np.sum(C[i,i]*p for i, p in enumerate(p_true))    \n",
    "\n",
    "def norm_row(M):\n",
    "    '''Check to be certain this isn't transpose of what's needed'''\n",
    "    row_sums = M.sum(axis=1).astype('float')\n",
    "    new_M = M /row_sums[:, np.newaxis]\n",
    "    return new_M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random distribution of 5 classes\n",
    "num_class = 5\n",
    "p_true = np.random.rand(num_class); p_true = p_true/ np.sum(p_true)\n",
    "\n",
    "num_classifier = 7\n",
    "\n",
    "# Generating 10,000 samples\n",
    "num_tot_samp = 10000\n",
    "stream_sample = np.arange(num_tot_samp)+1\n",
    "stream_true_label = np.random.choice(num_class, num_tot_samp, p = p_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ensemble of classifiers whose performance is simulated via\n",
    "# their confusion matrix\n",
    "ENS = fakeENS(num_classifier, num_class, stream_true_label)\n",
    "conf_mat = ENS.getConfMat()\n",
    "avg_acc = [averageAcc(p_true, conf_mat[i]) for i in range(num_classifier)]\n",
    "\n",
    "#print 'Min accuracy: %s'%str_arr(ENS.alpha)\n",
    "#print 'Avg accuracy: %s'%str_arr(avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.8, 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0.8, 0.3, 0.8],\n",
       "       [0.8, 0.5, 0.8, 0.8, 0.3],\n",
       "       [0.3, 0.8, 0.5, 0.8, 0.8],\n",
       "       [0.8, 0.5, 0.8, 0.8, 0.3],\n",
       "       [0.5, 0.5, 0.5, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0.5, 0.8, 0.5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENS.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4867779296991168,\n",
       " 0.40915825905136133,\n",
       " 0.42798571105957817,\n",
       " 0.3636007949193595,\n",
       " 0.4120559611005851,\n",
       " 0.5231671732703572,\n",
       " 0.4273833897527717]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
