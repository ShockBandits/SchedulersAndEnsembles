{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import cvxpy as cvx\n",
    "import traceback\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from Ensembles.Ensemble import Ensemble\n",
    "from Ensembles.Cifar10.Accessor.readCifar10 import *\n",
    "\n",
    "import import_ipynb\n",
    "from spectralEM import spectralEM\n",
    "from conflictGraph import conflictGraph\n",
    "from fakeENS import fakeENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbits(n, k):\n",
    "    result = []\n",
    "    for bits in itertools.combinations(range(n), k):\n",
    "        s = np.zeros(n)\n",
    "        for bit in bits:\n",
    "            s[bit] = 1\n",
    "        result.append(s)\n",
    "    return result\n",
    "\n",
    "def str_arr(arr, mode = 'float'):\n",
    "    if mode == 'int':\n",
    "        return \" \".join(\"%2d\"%x for x in arr)\n",
    "    else:\n",
    "        return \" \".join(\"%.3f\"%x for x in arr)\n",
    "def str_mat(mat):\n",
    "    return \"\\n\".join(str_arr(arr) for arr in mat) \n",
    "\n",
    "def averageAcc(p_true, C):\n",
    "    return np.sum(C[i,i]*p for i, p in enumerate(p_true))    \n",
    "\n",
    "def computeError(output_stream, true_label_stream):\n",
    "    if len(output_stream) == 0:\n",
    "        return 0\n",
    "    est_label = [o[1] for o in output_stream]\n",
    "    error = [(np.abs(x-y)>0.5) for x,y in zip(est_label, true_label_stream)]\n",
    "    error_frac = (np.sum(error)/float(len(error)))\n",
    "    return error_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfError(C_real, num_data, p_true, num_classifier, C_est, ph_est_avg):\n",
    "    errp = np.linalg.norm(p_true - ph_est_avg, 1)\n",
    "    err = [np.linalg.norm(C_real[k]- C_est[k], 1) for k in range(num_classifier)]\n",
    "    print '---------------------------'\n",
    "    print '*****Param Update*****'\n",
    "    print '---------------------------'\n",
    "    print 'Num samples:%d'%num_data\n",
    "    print 'True ph:%s'%str_arr(p_true)\n",
    "    print 'Est ph:%s'%str_arr(ph_est_avg)\n",
    "    print 'L1 error in class probability:%.3f'%errp\n",
    "    print 'Sum of L1 error in conf matrices:%.3f'%np.sum(err)\n",
    "    print '---------------------------'\n",
    "    return errp, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(data_set = 'Cifar10',\n",
    "              num_class = 3, num_classifier = 5,  # Ensemble and Data\n",
    "              load_ENS = False, fit_ENS = False, \n",
    "              load_params = True, save_params = False,# Ensemble\n",
    "              k_max_size = 3, # allowed subset \n",
    "              arr_rate = 0.8, thres = 0.75, V = 1, # arrival and departure thres\n",
    "              updateON = True, truePrior = False, # priors\n",
    "              time_slots = 1000 # simulation length\n",
    "             ):\n",
    "    '''\n",
    "    The function that simulates the system with the input parameters\n",
    "    \n",
    "    '''\n",
    "    #---------------------------------\n",
    "    #       ENS and Data\n",
    "    #---------------------------------\n",
    "    if load_ENS:\n",
    "        ENS=Ensemble(data_set)\n",
    "\n",
    "        # fit the ENS again\n",
    "        if fit_ENS:\n",
    "            ENS.get_train_data(); ENS.assign_members_train_data()\n",
    "            ENS.get_test_data(); ENS.assign_members_test_data()\n",
    "            ENS.create_classifiers(); ENS.fit_classifiers()\n",
    "            ENS.save_classifiers()\n",
    "        ENS.load_classifiers()\n",
    "        \n",
    "\n",
    "        '''    \n",
    "        try:\n",
    "            # fit the ENS again\n",
    "            if fit_ENS:\n",
    "                ENS.get_train_data(); ENS.assign_members_train_data()\n",
    "                ENS.get_test_data(); ENS.assign_members_test_data()\n",
    "                ENS.create_classifiers(); ENS.fit_classifiers()\n",
    "                ENS.save_classifiers()\n",
    "            ENS.load_classifiers()\n",
    "        except:\n",
    "            print 'Error in loading classifiers'\n",
    "            ENS.get_train_data(); ENS.assign_members_train_data()\n",
    "            ENS.get_test_data(); ENS.assign_members_test_data()\n",
    "            ENS.create_classifiers(); ENS.fit_classifiers()\n",
    "            ENS.save_classifiers()\n",
    "            ENS.load_classifiers()\n",
    "        '''    \n",
    "        ENS.get_train_data(); ENS.assign_members_train_data()\n",
    "        ENS.get_test_data(); ENS.assign_members_test_data()\n",
    "        ENS.create_classifiers() #Temp change until we get theano/tensorflow order from json files right\n",
    "        \n",
    "        # info about classifiers\n",
    "        name_classifier = ENS.import_name_classifier()\n",
    "        num_classifier = ENS.import_num_classifier()\n",
    "        num_class = ENS.import_num_class()\n",
    "        \n",
    "        # obtain the samples\n",
    "        true_labels = ENS.import_labels()\n",
    "        num_tot_samp_stream = len(true_labels)\n",
    "        samples = np.arange(num_tot_samp_stream)\n",
    "        \n",
    "        # permute the samples and the labels\n",
    "        perm_data = np.random.permutation(num_tot_samp_stream)\n",
    "        stream_true_labels = true_labels[perm_data] # Begins from 0\n",
    "        stream_sample = samples[perm_data] # Begins from 0\n",
    "        \n",
    "        # create arrival array and change time_slots if sample is less\n",
    "        arrival_arr = np.random.poisson(arr_rate, time_slots)\n",
    "        if np.sum(arrival_arr) > num_tot_samp_stream: \n",
    "            time_slots = np.argmax(np.cumsum(arrival_arr)> num_tot_samp_stream)-1\n",
    "        num_tot_samp = np.sum(arrival_arr[:time_slots])\n",
    "        \n",
    "        print 'Number of total samples in stream:%d'%num_tot_samp_stream\n",
    "        print 'Number of timeslots:%d'%time_slots\n",
    "        print 'Number of arrivals:%d'%num_tot_samp\n",
    "        print\n",
    "        \n",
    "        # obtain the parameters (w.r.t. test data)\n",
    "        if load_params:\n",
    "            trueConfMat = np.load('conf_mat.npy').item()\n",
    "            p_true = np.load('p_true.npy')\n",
    "        else:\n",
    "            trueConfMat = ENS.get_conf_matrix()\n",
    "            p_true = ENS.get_p_true()\n",
    "    else:\n",
    "        if load_params:\n",
    "            conf_mat = np.load('conf_mat.npy').item() \n",
    "            p_true = np.load('p_true.npy')\n",
    "            #print p_true\n",
    "            #print conf_mat.items()\n",
    "        else:\n",
    "            # probability of the various classes\n",
    "            p_const = 0.5\n",
    "            p_true = np.random.rand(num_class); \n",
    "            p_true = (p_const+p_true)/ np.sum(p_const+p_true)\n",
    "            conf_mat = None\n",
    "        #-----------------------------------\n",
    "        # synthetic dataset\n",
    "        name_classifier = ['syn-'+str(i) for i in range(num_classifier)]\n",
    "        ENS = fakeENS(num_classifier, num_class, confMat = conf_mat)\n",
    "        trueConfMat = ENS.getConfMat()\n",
    "        #------------------------------------\n",
    "        # beginning of the simulation\n",
    "        # can be restarted to rerun the simulation\n",
    "        # rerunning following blocks(including this one)\n",
    "        # do not change the capacity region\n",
    "        arrival_arr = np.random.poisson(arr_rate, time_slots)\n",
    "        num_tot_samp = np.sum(arrival_arr) \n",
    "\n",
    "        # generate the samples(both begins from 0)\n",
    "        stream_sample = np.arange(num_tot_samp) \n",
    "        stream_true_labels = np.random.choice(num_class,\n",
    "                                              num_tot_samp, p = p_true)\n",
    "        \n",
    "        # feed samples to the ensemble\n",
    "        ENS.newSamples(stream_true_labels) \n",
    "        # re-randomize the output label mapping\n",
    "        ENS.reshuffle() \n",
    "    #--------------------------------------------------------\n",
    "    #.         Display Ensemble and Data\n",
    "    #-------------------------------------------------------- \n",
    "    if save_params:\n",
    "        np.save('conf_mat.npy', trueConfMat)\n",
    "        np.save('p_true.npy', p_true)\n",
    "    #-----------------------------------\n",
    "    print \"Number of class:%d\"%num_class\n",
    "    print \"Number of classifiers:%d\"%num_classifier\n",
    "    print \"Name of classifiers:\",name_classifier\n",
    "    print 'True label probability:', p_true\n",
    "    print 'True conf matrices'\n",
    "    for i, mat in enumerate(trueConfMat.values()): \n",
    "        print 'Classifier:%s'%name_classifier[i]\n",
    "        print str_mat(mat)\n",
    "        print\n",
    "    #--------------------------------------------------------\n",
    "    #.         Conflict Graph and Spectral Estimator\n",
    "    #--------------------------------------------------------\n",
    "    # init params for spectral estimator and the conflict graph\n",
    "    params = {}\n",
    "    unip = np.ones(num_class)/float(num_class);\n",
    "    # the initial conf matries\n",
    "    expert_frac = 0.01\n",
    "    expertConfMat = {j: (expert_frac)*np.eye(num_class)+ \n",
    "                     (1-expert_frac)*np.tile(unip, [num_class, 1])\n",
    "                     for j in range(num_classifier)}\n",
    "    if truePrior:\n",
    "        # True prior\n",
    "        params['Confmat'] = trueConfMat\n",
    "        params['p_true'] = p_true\n",
    "    else:\n",
    "        # expert prior with uniform label porbabilities\n",
    "        params['Confmat'] = expertConfMat\n",
    "        params['p_true'] = unip\n",
    "    #---------display: current parameter error--------------\n",
    "    est_err = ConfError(trueConfMat, 0, p_true, num_classifier, \n",
    "                         params['Confmat'], params['p_true'])\n",
    "    \n",
    "    true_avg_acc = [averageAcc(p_true, trueConfMat[i]) for i in range(num_classifier)]\n",
    "    init_avg_acc = [averageAcc(p_true, params['Confmat'][i]) for i in range(num_classifier)]\n",
    "    print 'True Avg accuracy: %s'%str_arr(true_avg_acc)\n",
    "    print 'Initial Avg accuracy: %s'%str_arr([averageAcc(p_true, params['Confmat'][i]) \n",
    "                                              for i in range(num_classifier)])\n",
    "    \n",
    "    #                Allowed subsets\n",
    "    \n",
    "    k_max_size = min(num_classifier-1, k_max_size)\n",
    "    k_max = [num_classifier]\n",
    "    for kms in range(k_max_size):\n",
    "        k_max.append(int(kms+1))\n",
    "        k_max.append(num_classifier - int(kms+1))\n",
    "    k_max = list(set(k_max))\n",
    "    \n",
    "    allowed_subset = []\n",
    "    for k in k_max:\n",
    "        allowed_subset += kbits(int(num_classifier), int(k))\n",
    "    \n",
    "    #           Create the conflict graph\n",
    "    \n",
    "    disp = 100    # disp parameter for conflict Graph\n",
    "    G = conflictGraph(allowed_subset = allowed_subset, M = num_classifier, \n",
    "                      C = num_class, Ens= ENS, params = params, \n",
    "                      V = V, thres = thres, disp = disp)\n",
    "    \n",
    "    #          Create the spectral estimator\n",
    "    \n",
    "    S = spectralEM(num_classifier, num_class, maxiter = 500, num_init = 100)\n",
    "    \n",
    "    #          Compute metrics for Spectral estimation\n",
    "    \n",
    "    group = S.group \n",
    "    groupConfMat = {i: np.mean([trueConfMat[j] for j in range(num_classifier) if group[i][j]], axis = 0)  \n",
    "                    for i in range(3)}\n",
    "\n",
    "    # Quantifies quality of individual classifiers in confusion matrix\n",
    "    kappa = np.min([np.min([[groupConfMat[j][l,l] - groupConfMat[j][l,c] for c in range(num_class) if c !=l] \n",
    "                          for l in range(num_class)]) for j in range(3)])\n",
    "\n",
    "\n",
    "    # Quantifies ensemble quality - independence of classifiers\n",
    "    barD = np.min([[np.mean([entropy(trueConfMat[i][l,:], trueConfMat[j][l,:]) \n",
    "                             for i in range(num_classifier)]) \n",
    "                    for c in range(num_class) if c !=l] \n",
    "                   for l in range(num_class)])\n",
    "    \n",
    "    #Display: metrics for spectral estimation\n",
    "    print 'Metrics in Spectral Learning| kappa:%.3f, barD:%.3f'%(kappa, barD)\n",
    "    print\n",
    "    \n",
    "    #display: allowed subsets\n",
    "    print 'Allowed all subsets of size:',k_max\n",
    "\n",
    "    #              Reset Internal States\n",
    "    \n",
    "    G.reset() # resets the internal queues\n",
    "    S.reset() # resets the internal parameters\n",
    "\n",
    "    #       Exploration and estimation parameters \n",
    "    \n",
    "    update_num = 25 # lenght of explore_data when S is updated\n",
    "    updateSpectral = True # no spectral updates (only EM)\n",
    "    # make the following two 0 to stop exploration\n",
    "    explore_prob_const = 0.1 # probability with which exploration happens\n",
    "    init_explore = 200 # Number of initial time slots when explore happens\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    # Initialization\n",
    "    output_stream= []\n",
    "    true_label_stream = []\n",
    "    queue_evol = []\n",
    "    error_evol = []\n",
    "    est_evol = []\n",
    "\n",
    "    samp_count = 0\n",
    "    tau = 0 \n",
    "    explore_data = []\n",
    "    count_update = 0\n",
    "    \n",
    "    # display period\n",
    "    disp_period = 25\n",
    "    display = 2 # display flag\n",
    "    \n",
    "    print 'Arrival Rate:', arr_rate, 'Accuracy Threshold:', G.thres\n",
    "    print 'Total samples:', num_tot_samp, 'Total time slots:', time_slots\n",
    "    #--------------------------------------\n",
    "    #            Iterations\n",
    "    #--------------------------------------\n",
    "    print '----------\\nIterations Begin\\n-----------' \n",
    "    while len(output_stream)< num_tot_samp:\n",
    "        #----arrival-----\n",
    "        if tau < time_slots:\n",
    "            # sample id should begin from 1 while providing newArrival\n",
    "            G.newArrival(stream_sample[samp_count:samp_count+arrival_arr[tau]]+1)\n",
    "            samp_count += arrival_arr[tau]\n",
    "        \n",
    "        #----------------------------------------------------------\n",
    "        #                  Exploit or Explore: Scheduling\n",
    "        #----------------------------------------------------------\n",
    "        \n",
    "        #                set explore probability \n",
    "        \n",
    "        # default\n",
    "        explore_prob = explore_prob_const # explore_prob_const*np.log(i)/i\n",
    "        # explore for the first 100 rounds\n",
    "        explore_prob = 1.0 if tau < init_explore else explore_prob\n",
    "        # explore only if updateON\n",
    "        explore_flag = (np.random.rand() < explore_prob) and updateON\n",
    "        \n",
    "        #                 schedule\n",
    "        \n",
    "        try:\n",
    "            sample_out, schedule, _ = G.schedule(explore = explore_flag)\n",
    "        except Exception as e:\n",
    "            print '***Error in Scheduling***Exiting***'\n",
    "            traceback.print_exc(); break\n",
    "\n",
    "        #----------------------------------------------------------\n",
    "        #                  Update Parameters\n",
    "        #----------------------------------------------------------\n",
    "        if updateON: # update on each output\n",
    "        #if explore_flag: # update on exploration instances\n",
    "            explore_data += [s[2]-1 for s in sample_out]\n",
    "            \n",
    "        if (len(explore_data) >= update_num) and updateON:\n",
    "            \n",
    "            #         update the spectralEM object\n",
    "            \n",
    "            S.update(explore_data);\n",
    "            \n",
    "            #          recallibrate params using Spectral\n",
    "            \n",
    "            if (tau > init_explore) and updateSpectral:\n",
    "                S.updateParamsSpectral()\n",
    "                count_update +=1\n",
    "                \n",
    "            #           update params using EM\n",
    "            \n",
    "            S.updateParamsEM(explore_data);\n",
    "            \n",
    "            #           update G params\n",
    "            \n",
    "            new_params = {'Confmat': S.conf_mat, 'p_true': S.ph_est_avg}\n",
    "            G.updateParams(new_params)\n",
    "            \n",
    "            #            compute error \n",
    "            \n",
    "            est_err = ConfError(trueConfMat, S.num_data, p_true, \n",
    "                           num_classifier, S.conf_mat, S.ph_est_avg)\n",
    "            \n",
    "            #           empty explore_data \n",
    "            \n",
    "            explore_data = []\n",
    "        #----------------------------------------------------------       \n",
    "        #                    Results\n",
    "        #----------------------------------------------------------\n",
    "        true_label_out = []\n",
    "        for s in sample_out:\n",
    "            ind_s, = np.where(stream_sample == int(s[0]-1))\n",
    "            if stream_sample[ind_s] != int(s[0]-1): \n",
    "                print \"Error in finding sample location\"\n",
    "                true_label_out += [-1]\n",
    "            else:\n",
    "                true_label_out += [stream_true_labels[ind_s]+1]\n",
    "            \n",
    "        rem_samples = G.totalCount()\n",
    "        output_stream += sample_out\n",
    "        tot_queue = G.totalCount()\n",
    "        true_label_stream += true_label_out\n",
    "        classification_error = computeError(output_stream, true_label_stream)\n",
    "\n",
    "        queue_evol.append(tot_queue) \n",
    "        error_evol.append(classification_error)\n",
    "        est_evol.append(est_err)\n",
    "        #----------------------------------------------------------       \n",
    "        #                   Display\n",
    "        #----------------------------------------------------------\n",
    "        if not np.mod(tau, disp_period): \n",
    "            print '--------------------'\n",
    "            print 'num iterations:', tau;\n",
    "            print 'Total samples in queues:', G.totalCount()\n",
    "            print 'Total samples in explore list:', len(explore_data)\n",
    "            print 'Number of outputs:', len(output_stream)\n",
    "            print 'Error fraction:%.3f'%classification_error\n",
    "            print '-------------------'\n",
    "        if display <= 1:\n",
    "           \n",
    "            G.print_labelSubsets()\n",
    "            print \n",
    "        if display <= 2:\n",
    "            print 'Iteration:', tau, 'Total Queue Length:', tot_queue\n",
    "            print 'Schedule:', schedule\n",
    "            print 'Output'\n",
    "            for i_s, s in enumerate(sample_out):\n",
    "                # s: sample_id, label_final, label_arr, label_conf\n",
    "                print \" \".join(['Sample Id:%4d'%s[0],\n",
    "                                'Labels=> Real:%2d'%(true_label_out[i_s]), \n",
    "                                'Final:%2d'%s[1], 'Conf:%.3f'%s[3],\n",
    "                                'All: %s'%str_arr(s[2], 'int')])\n",
    "            print\n",
    "                \n",
    "        #  increase the time count\n",
    "        \n",
    "        tau += 1\n",
    "    #----------------------outputs-----------\n",
    "    output_dict = {}\n",
    "    output_dict['tau'] = tau\n",
    "    output_dict['time_slots'] = time_slots\n",
    "    output_dict['arrival_arr'] = arrival_arr\n",
    "    output_dict['output_stream'] = output_stream\n",
    "    output_dict['true_label_stream'] = true_label_stream\n",
    "    output_dict['queue_evol'] = queue_evol\n",
    "    output_dict['error_evol'] = error_evol\n",
    "    output_dict['est_evol'] = est_evol\n",
    "    output_dict['rem_samples'] = rem_samples\n",
    "    #-------------------------------------------\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayResults(output_dict):\n",
    "    tau = output_dict['tau']\n",
    "    arrival_arr = output_dict['arrival_arr']\n",
    "    time_slots = output_dict['time_slots']\n",
    "    output_stream = output_dict['output_stream'] \n",
    "    true_label_stream = output_dict['true_label_stream']\n",
    "    queue_evol = output_dict['queue_evol']\n",
    "    error_evol = output_dict['error_evol']\n",
    "    est_evol = output_dict['est_evol'] \n",
    "    rem_samples = output_dict['rem_samples'] \n",
    "    #-------------------------------------------------------\n",
    "    print 'Remaining Samples:', rem_samples\n",
    "    print 'Len O/p Stream:', len(output_stream)\n",
    "    error_frac = computeError(output_stream, true_label_stream)\n",
    "    print '-------\\nFinal Output\\n--------'\n",
    "    print 'All samples cleared after no. iterations:',tau\n",
    "    print 'Accuracy:%.3f'%(1- error_frac)\n",
    "    print 'Time average of total Queue Length:%.2f'%np.mean(queue_evol)\n",
    "\n",
    "    if tau <= (time_slots):\n",
    "        arrival_arr_pad = arrival_arr[:tau]\n",
    "    else:\n",
    "        arrival_arr_pad = np.array(list(arrival_arr) + list(np.zeros(tau - time_slots)))\n",
    "\n",
    "    plt.plot(range(tau), arrival_arr_pad, 'b-', range(tau), queue_evol, 'r--')\n",
    "    plt.legend(['Arrival', 'Total Queue Length'])\n",
    "    plt.title('Arrival and Evolution of Queues')\n",
    "    plt.xlabel('timeslot')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(range(tau), [1-e for e in error_evol], 'b-')\n",
    "    plt.title('Evolution of Classification Accuracy')\n",
    "    plt.xlabel('timeslot')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(tau), [e[0] for e in est_evol], 'b-', range(tau),[np.mean(e[1]) for e in est_evol] , 'r--')\n",
    "    plt.legend(['p_true', 'conf mat'])\n",
    "    plt.title('Evolution of Estimation Error')\n",
    "    plt.xlabel('timeslot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config Info For RandomForest - RFC_0.cfg\n",
      "Loaded Config Info For ResNetV1 - RNV1_0.cfg\n",
      "Loaded Config Info For ResNetV2 - RNV2_0.cfg\n",
      "Loaded Config Info For SimpleCNN - SCNN_0.cfg\n",
      "Loaded Config Info For XGBoost - XGBC_0.cfg\n",
      "\n",
      "\n",
      "Loading Classifiers\n",
      "Read  /home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/results_dir/SCNN_0.pkl\n",
      "Read  /home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/results_dir/RFC_0_test.pkl\n",
      "Read  /home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/results_dir/XGBC_0_test.pkl\n",
      "Read  /home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/results_dir/RNV1_0.pkl\n",
      "Read  /home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/results_dir/RNV2_0.pkl\n",
      "\n",
      "\n",
      "Getting Train Data\n",
      "Geting data for SimpleCNN\n",
      "Geting data for RandomForest\n",
      "Geting data for XGBoost\n",
      "Geting data for ResNetV1\n",
      "Geting data for ResNetV2\n",
      "\n",
      "Getting Test Data\n",
      "Geting data for SimpleCNN\n",
      "Geting data for RandomForest\n",
      "Geting data for XGBoost\n",
      "Geting data for ResNetV1\n",
      "Geting data for ResNetV2\n",
      "\n",
      "Creating Classifiers\n",
      "('Learning rate: ', 0.001)\n",
      "('Learning rate: ', 0.001)\n",
      "\n",
      "\n",
      "Number of total samples in stream:10000\n",
      "Number of timeslots:200\n",
      "Number of arrivals:329\n",
      "\n",
      "Geting conf_matrix\n",
      "Geting conf_matrix for RandomForest-0\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-73c0dc201329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0marr_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m# arrival and departure thres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mupdateON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruePrior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                   time_slots = 200)# simulation length\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Display the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdisplayResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f2dd77c89374>\u001b[0m in \u001b[0;36msimulator\u001b[0;34m(data_set, num_class, num_classifier, load_ENS, fit_ENS, load_params, save_params, k_max_size, arr_rate, thres, V, updateON, truePrior, time_slots)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mp_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p_true.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtrueConfMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mp_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_p_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Ensemble.py\u001b[0m in \u001b[0;36mget_conf_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Geting conf_matrix for %s-%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_clfr_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     conf_matrices[count] = clfr.get_conf_matrix(clfr.test_data,\n\u001b[0;32m--> 178\u001b[0;31m                                                                 clfr.test_labels)\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconf_matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/innovationcommons/InnovCommon_Projects/Shakkotai/SoumyaRepo/Packing UEL/Ensembles/Cifar10/Classifiers/RandomForest.pyc\u001b[0m in \u001b[0;36mget_conf_matrix\u001b[0;34m(self, data, true_labels)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_conf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Error, the number of true labels != number of predicted labels\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/innovationcommons/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/innovationcommons/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/innovationcommons/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    # Compute the results \n",
    "    output_dict = simulator(num_class = 3, num_classifier = 5,  # Ensemble and Data\n",
    "                  load_ENS = True, fit_ENS = False, \n",
    "                  load_params = False, save_params = False, # Ensemble\n",
    "                  k_max_size = 3, # allowed subset \n",
    "                  arr_rate = 1.6, thres = 0.6, V = 0,# arrival and departure thres\n",
    "                  updateON = True, truePrior = True, # priors\n",
    "                  time_slots = 200)# simulation length\n",
    "    # Display the results    \n",
    "    displayResults(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
